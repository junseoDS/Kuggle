{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Read data...')\n",
    "\n",
    "train =  pd.read_csv('NY_taxi/train.csv')\n",
    "test =  pd.read_csv('NY_taxi/test.csv')\n",
    "train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])\n",
    "test['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'])\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train['store_and_fwd_flag'])\n",
    "train['store_and_fwd_flag'] = le.transform(train['store_and_fwd_flag'])\n",
    "test['store_and_fwd_flag'] = le.transform(test['store_and_fwd_flag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Create features...')\n",
    "train['month'] = train['pickup_datetime'].dt.month\n",
    "train['day'] = train['pickup_datetime'].dt.day\n",
    "train['weekday'] = train['pickup_datetime'].dt.weekday\n",
    "train['hour'] = train['pickup_datetime'].dt.hour\n",
    "train['minute'] = train['pickup_datetime'].dt.minute\n",
    "\n",
    "test['month'] = test['pickup_datetime'].dt.month\n",
    "test['day'] = test['pickup_datetime'].dt.day\n",
    "test['weekday'] = test['pickup_datetime'].dt.weekday\n",
    "test['hour'] = test['pickup_datetime'].dt.hour\n",
    "test['minute'] = test['pickup_datetime'].dt.minute\n",
    "\n",
    "#### distance features\n",
    "train['dist_long'] = train['pickup_longitude'] - train['dropoff_longitude']\n",
    "test['dist_long'] = test['pickup_longitude'] - test['dropoff_longitude']\n",
    "\n",
    "train['dist_lat'] = train['pickup_latitude'] - train['dropoff_latitude']\n",
    "test['dist_lat'] = test['pickup_latitude'] - test['dropoff_latitude']\n",
    "\n",
    "train['dist'] = np.sqrt(np.square(train['dist_long']) + np.square(train['dist_lat']))\n",
    "test['dist'] = np.sqrt(np.square(test['dist_long']) + np.square(test['dist_lat']))\n",
    "\n",
    "#### spatial features: count and speed\n",
    "train['pickup_longitude_bin'] = np.round(train['pickup_longitude'], 2)\n",
    "train['pickup_latitude_bin'] = np.round(train['pickup_latitude'], 2)\n",
    "train['dropoff_longitude_bin'] = np.round(train['dropoff_longitude'], 2)\n",
    "train['dropoff_latitude_bin'] = np.round(train['dropoff_latitude'], 2)\n",
    "\n",
    "test['pickup_longitude_bin'] = np.round(test['pickup_longitude'], 2)\n",
    "test['pickup_latitude_bin'] = np.round(test['pickup_latitude'], 2)\n",
    "test['dropoff_longitude_bin'] = np.round(test['dropoff_longitude'], 2)\n",
    "test['dropoff_latitude_bin'] = np.round(test['dropoff_latitude'], 2)\n",
    "\n",
    "## count features\n",
    "a = pd.concat([train,test]).groupby(['pickup_longitude_bin', 'pickup_latitude_bin']).size().reset_index()\n",
    "b = pd.concat([train,test]).groupby(['dropoff_longitude_bin', 'dropoff_latitude_bin']).size().reset_index()\n",
    "\n",
    "train = pd.merge(train, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "\n",
    "train = pd.merge(train, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\n",
    "\n",
    "## speed features\n",
    "train['speed'] = 100000*train['dist'] / train['trip_duration']\n",
    "\n",
    "a = train[['speed', 'pickup_longitude_bin', 'pickup_latitude_bin']].groupby(['pickup_longitude_bin', 'pickup_latitude_bin']).mean().reset_index()\n",
    "a = a.rename(columns = {'speed': 'ave_speed'})\n",
    "b = train[['speed', 'dropoff_longitude_bin', 'dropoff_latitude_bin']].groupby(['dropoff_longitude_bin', 'dropoff_latitude_bin']).mean().reset_index()\n",
    "b = b.rename(columns = {'speed': 'ave_speed'})\n",
    "\n",
    "train = pd.merge(train, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "\n",
    "train = pd.merge(train, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\n",
    "\n",
    "## drop bins\n",
    "train = train.drop(['speed', 'pickup_longitude_bin', 'pickup_latitude_bin', 'dropoff_longitude_bin', 'dropoff_latitude_bin'], axis = 1)\n",
    "test = test.drop(['pickup_longitude_bin', 'pickup_latitude_bin', 'dropoff_longitude_bin', 'dropoff_latitude_bin'], axis = 1)\n",
    "\n",
    "#### weather data\n",
    "weather = pd.read_csv('NY_taxi/KNYC_Metars.csv')\n",
    "weather['Time'] = pd.to_datetime(weather['Time'])\n",
    "weather['year'] = weather['Time'].dt.year\n",
    "weather['month'] = weather['Time'].dt.month\n",
    "weather['day'] = weather['Time'].dt.day\n",
    "weather['hour'] = weather['Time'].dt.hour\n",
    "weather = weather[weather['year'] == 2016]\n",
    "\n",
    "train = pd.merge(train, weather[['Temp.', 'month', 'day', 'hour']], on = ['month', 'day', 'hour'], how = 'left')\n",
    "test = pd.merge(test, weather[['Temp.', 'month', 'day', 'hour']], on = ['month', 'day', 'hour'], how = 'left')\n",
    "\n",
    "## train/test features, y, id\n",
    "xtrain = train.drop(['id', 'pickup_datetime', 'dropoff_datetime', 'trip_duration'], axis = 1).as_matrix()\n",
    "xtest = test.drop(['id', 'pickup_datetime', ], axis = 1).as_matrix()\n",
    "ytrain = train['trip_duration'].values\n",
    "id_train = train['id'].values\n",
    "id_test = test['id'].values\n",
    "del(train, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'booster':            'gbtree',\n",
    "    'objective':          'reg:linear',\n",
    "    'learning_rate':      0.1,\n",
    "    'max_depth':          14,\n",
    "    'subsample':          0.8,\n",
    "    'colsample_bytree':   0.7,\n",
    "    'colsample_bylevel':  0.7,\n",
    "    'silent':             1\n",
    "}\n",
    "\n",
    "## number of rounds\n",
    "nrounds = 200\n",
    "\n",
    "## train model\n",
    "print('Train model...')\n",
    "dtrain = xgb.DMatrix(xtrain, np.log(ytrain+1))\n",
    "gbm = xgb.train(params,\n",
    "                dtrain,\n",
    "                num_boost_round = nrounds)\n",
    "\n",
    "## test predictions\n",
    "pred_test = np.exp(gbm.predict(xgb.DMatrix(xtest))) - 1\n",
    "\n",
    "## create submission\n",
    "df = pd.DataFrame({'id': id_test, 'trip_duration': pred_test}) \n",
    "df = df.set_index('id')\n",
    "df.to_csv('sub_bench.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data...\n",
      "Create features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\ku\\lib\\site-packages\\ipykernel_launcher.py:59: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Users\\User\\Anaconda3\\envs\\ku\\lib\\site-packages\\ipykernel_launcher.py:60: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Users\\User\\Anaconda3\\envs\\ku\\lib\\site-packages\\ipykernel_launcher.py:99: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\User\\Anaconda3\\envs\\ku\\lib\\site-packages\\ipykernel_launcher.py:100: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print('Read data...')\n",
    "\n",
    "train =  pd.read_csv('NY_taxi/train.csv')\n",
    "test =  pd.read_csv('NY_taxi/test.csv')\n",
    "train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])\n",
    "test['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'])\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train['store_and_fwd_flag'])\n",
    "train['store_and_fwd_flag'] = le.transform(train['store_and_fwd_flag'])\n",
    "test['store_and_fwd_flag'] = le.transform(test['store_and_fwd_flag'])\n",
    "\n",
    "print('Create features...')\n",
    "train['month'] = train['pickup_datetime'].dt.month\n",
    "train['day'] = train['pickup_datetime'].dt.day\n",
    "train['weekday'] = train['pickup_datetime'].dt.weekday\n",
    "train['hour'] = train['pickup_datetime'].dt.hour\n",
    "train['minute'] = train['pickup_datetime'].dt.minute\n",
    "\n",
    "test['month'] = test['pickup_datetime'].dt.month\n",
    "test['day'] = test['pickup_datetime'].dt.day\n",
    "test['weekday'] = test['pickup_datetime'].dt.weekday\n",
    "test['hour'] = test['pickup_datetime'].dt.hour\n",
    "test['minute'] = test['pickup_datetime'].dt.minute\n",
    "\n",
    "#### distance features\n",
    "train['dist_long'] = train['pickup_longitude'] - train['dropoff_longitude']\n",
    "test['dist_long'] = test['pickup_longitude'] - test['dropoff_longitude']\n",
    "\n",
    "train['dist_lat'] = train['pickup_latitude'] - train['dropoff_latitude']\n",
    "test['dist_lat'] = test['pickup_latitude'] - test['dropoff_latitude']\n",
    "\n",
    "train['dist'] = np.sqrt(np.square(train['dist_long']) + np.square(train['dist_lat']))\n",
    "test['dist'] = np.sqrt(np.square(test['dist_long']) + np.square(test['dist_lat']))\n",
    "\n",
    "#### spatial features: count and speed\n",
    "train['pickup_longitude_bin'] = np.round(train['pickup_longitude'], 2)\n",
    "train['pickup_latitude_bin'] = np.round(train['pickup_latitude'], 2)\n",
    "train['dropoff_longitude_bin'] = np.round(train['dropoff_longitude'], 2)\n",
    "train['dropoff_latitude_bin'] = np.round(train['dropoff_latitude'], 2)\n",
    "\n",
    "test['pickup_longitude_bin'] = np.round(test['pickup_longitude'], 2)\n",
    "test['pickup_latitude_bin'] = np.round(test['pickup_latitude'], 2)\n",
    "test['dropoff_longitude_bin'] = np.round(test['dropoff_longitude'], 2)\n",
    "test['dropoff_latitude_bin'] = np.round(test['dropoff_latitude'], 2)\n",
    "\n",
    "## count features\n",
    "a = pd.concat([train,test]).groupby(['pickup_longitude_bin', 'pickup_latitude_bin']).size().reset_index()\n",
    "b = pd.concat([train,test]).groupby(['dropoff_longitude_bin', 'dropoff_latitude_bin']).size().reset_index()\n",
    "\n",
    "train = pd.merge(train, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "\n",
    "train = pd.merge(train, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\n",
    "\n",
    "## speed features\n",
    "train['speed'] = 100000*train['dist'] / train['trip_duration']\n",
    "\n",
    "a = train[['speed', 'pickup_longitude_bin', 'pickup_latitude_bin']].groupby(['pickup_longitude_bin', 'pickup_latitude_bin']).mean().reset_index()\n",
    "a = a.rename(columns = {'speed': 'ave_speed'})\n",
    "b = train[['speed', 'dropoff_longitude_bin', 'dropoff_latitude_bin']].groupby(['dropoff_longitude_bin', 'dropoff_latitude_bin']).mean().reset_index()\n",
    "b = b.rename(columns = {'speed': 'ave_speed'})\n",
    "\n",
    "train = pd.merge(train, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "\n",
    "train = pd.merge(train, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\n",
    "\n",
    "## drop bins\n",
    "train = train.drop(['speed', 'pickup_longitude_bin', 'pickup_latitude_bin', 'dropoff_longitude_bin', 'dropoff_latitude_bin'], axis = 1)\n",
    "test = test.drop(['pickup_longitude_bin', 'pickup_latitude_bin', 'dropoff_longitude_bin', 'dropoff_latitude_bin'], axis = 1)\n",
    "\n",
    "#### weather data\n",
    "weather = pd.read_csv('NY_taxi/KNYC_Metars.csv')\n",
    "weather['Time'] = pd.to_datetime(weather['Time'])\n",
    "weather['year'] = weather['Time'].dt.year\n",
    "weather['month'] = weather['Time'].dt.month\n",
    "weather['day'] = weather['Time'].dt.day\n",
    "weather['hour'] = weather['Time'].dt.hour\n",
    "weather = weather[weather['year'] == 2016]\n",
    "\n",
    "train = pd.merge(train, weather[['Temp.', 'month', 'day', 'hour']], on = ['month', 'day', 'hour'], how = 'left')\n",
    "test = pd.merge(test, weather[['Temp.', 'month', 'day', 'hour']], on = ['month', 'day', 'hour'], how = 'left')\n",
    "\n",
    "## train/test features, y, id\n",
    "xtrain = train.drop(['id', 'pickup_datetime', 'dropoff_datetime', 'trip_duration'], axis = 1).as_matrix()\n",
    "xtest = test.drop(['id', 'pickup_datetime', ], axis = 1).as_matrix()\n",
    "ytrain = train['trip_duration'].values\n",
    "id_train = train['id'].values\n",
    "id_test = test['id'].values\n",
    "del(train, test)\n",
    "\n",
    "## xgb parameters\n",
    "params = {\n",
    "    'booster':            'gbtree',\n",
    "    'objective':          'reg:linear',\n",
    "    'learning_rate':      0.1,\n",
    "    'max_depth':          14,\n",
    "    'subsample':          0.8,\n",
    "    'colsample_bytree':   0.7,\n",
    "    'colsample_bylevel':  0.7,\n",
    "    'silent':             1\n",
    "}\n",
    "\n",
    "## number of rounds\n",
    "nrounds = 200\n",
    "\n",
    "## train model\n",
    "print('Train model...')\n",
    "dtrain = xgb.DMatrix(xtrain, np.log(ytrain+1))\n",
    "gbm = xgb.train(params,\n",
    "                dtrain,\n",
    "                num_boost_round = nrounds)\n",
    "\n",
    "## test predictions\n",
    "pred_test = np.exp(gbm.predict(xgb.DMatrix(xtest))) - 1\n",
    "\n",
    "## create submission\n",
    "df = pd.DataFrame({'id': id_test, 'trip_duration': pred_test}) \n",
    "df = df.set_index('id')\n",
    "df.to_csv('sub_bench.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ku",
   "language": "python",
   "name": "ku"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
